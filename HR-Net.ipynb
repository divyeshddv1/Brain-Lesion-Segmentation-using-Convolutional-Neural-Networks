{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "import logging\n",
    "import pickle\n",
    "import yaml\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Function, Variable\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla K80'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "BN_MOMENTUM = 0.1\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv3d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm3d(planes, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm3d(planes, momentum=BN_MOMENTUM)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv3d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv3 = nn.Conv3d(planes, planes * self.expansion, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * self.expansion,\n",
    "                                  momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighResolutionModule(nn.Module):\n",
    "    def __init__(self, num_branches, blocks, num_blocks, num_inchannels,\n",
    "                 num_channels, fuse_method, multi_scale_output=True):\n",
    "        super(HighResolutionModule, self).__init__()\n",
    "        self._check_branches(\n",
    "            num_branches, blocks, num_blocks, num_inchannels, num_channels)\n",
    "\n",
    "        self.num_inchannels = num_inchannels\n",
    "        self.fuse_method = fuse_method\n",
    "        self.num_branches = num_branches\n",
    "\n",
    "        self.multi_scale_output = multi_scale_output\n",
    "\n",
    "        self.branches = self._make_branches(\n",
    "            num_branches, blocks, num_blocks, num_channels)\n",
    "        self.fuse_layers = self._make_fuse_layers()\n",
    "        self.relu = nn.ReLU(True)\n",
    "\n",
    "    def _check_branches(self, num_branches, blocks, num_blocks,\n",
    "                        num_inchannels, num_channels):\n",
    "        if num_branches != len(num_blocks):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_BLOCKS({})'.format(\n",
    "                num_branches, len(num_blocks))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        if num_branches != len(num_channels):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_CHANNELS({})'.format(\n",
    "                num_branches, len(num_channels))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        if num_branches != len(num_inchannels):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_INCHANNELS({})'.format(\n",
    "                num_branches, len(num_inchannels))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "    def _make_one_branch(self, branch_index, block, num_blocks, num_channels,\n",
    "                         stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or \\\n",
    "           self.num_inchannels[branch_index] != num_channels[branch_index] * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(\n",
    "                    self.num_inchannels[branch_index],\n",
    "                    num_channels[branch_index] * block.expansion,\n",
    "                    kernel_size=1, stride=stride, bias=False\n",
    "                ),\n",
    "                nn.BatchNorm3d(\n",
    "                    num_channels[branch_index] * block.expansion,\n",
    "                    momentum=BN_MOMENTUM\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.num_inchannels[branch_index],\n",
    "                num_channels[branch_index],\n",
    "                stride,\n",
    "                downsample\n",
    "            )\n",
    "        )\n",
    "        self.num_inchannels[branch_index] = \\\n",
    "            num_channels[branch_index] * block.expansion\n",
    "        for i in range(1, num_blocks[branch_index]):\n",
    "            layers.append(\n",
    "                block(\n",
    "                    self.num_inchannels[branch_index],\n",
    "                    num_channels[branch_index]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_branches(self, num_branches, block, num_blocks, num_channels):\n",
    "        branches = []\n",
    "\n",
    "        for i in range(num_branches):\n",
    "            branches.append(\n",
    "                self._make_one_branch(i, block, num_blocks, num_channels)\n",
    "            )\n",
    "\n",
    "        return nn.ModuleList(branches)\n",
    "\n",
    "    def _make_fuse_layers(self):\n",
    "        if self.num_branches == 1:\n",
    "            return None\n",
    "\n",
    "        num_branches = self.num_branches\n",
    "        num_inchannels = self.num_inchannels\n",
    "        fuse_layers = []\n",
    "        for i in range(num_branches if self.multi_scale_output else 1):\n",
    "            fuse_layer = []\n",
    "            for j in range(num_branches):\n",
    "                if j > i:\n",
    "                    fuse_layer.append(\n",
    "                        nn.Sequential(\n",
    "                            nn.Conv3d(\n",
    "                                num_inchannels[j],\n",
    "                                num_inchannels[i],\n",
    "                                1, 1, 0, bias=False\n",
    "                            ),\n",
    "                            nn.BatchNorm3d(num_inchannels[i]),\n",
    "                            nn.Upsample(scale_factor=2**(j-i), mode='nearest')\n",
    "                        )\n",
    "                    )\n",
    "                elif j == i:\n",
    "                    fuse_layer.append(None)\n",
    "                else:\n",
    "                    conv3x3s = []\n",
    "                    for k in range(i-j):\n",
    "                        if k == i - j - 1:\n",
    "                            num_outchannels_conv3x3 = num_inchannels[i]\n",
    "                            conv3x3s.append(\n",
    "                                nn.Sequential(\n",
    "                                    nn.Conv3d(\n",
    "                                        num_inchannels[j],\n",
    "                                        num_outchannels_conv3x3,\n",
    "                                        3, 2, 1, bias=False\n",
    "                                    ),\n",
    "                                    nn.BatchNorm3d(num_outchannels_conv3x3)\n",
    "                                )\n",
    "                            )\n",
    "                        else:\n",
    "                            num_outchannels_conv3x3 = num_inchannels[j]\n",
    "                            conv3x3s.append(\n",
    "                                nn.Sequential(\n",
    "                                    nn.Conv3d(\n",
    "                                        num_inchannels[j],\n",
    "                                        num_outchannels_conv3x3,\n",
    "                                        3, 2, 1, bias=False\n",
    "                                    ),\n",
    "                                    nn.BatchNorm3d(num_outchannels_conv3x3),\n",
    "                                    nn.ReLU(True)\n",
    "                                )\n",
    "                            )\n",
    "                    fuse_layer.append(nn.Sequential(*conv3x3s))\n",
    "            fuse_layers.append(nn.ModuleList(fuse_layer))\n",
    "\n",
    "        return nn.ModuleList(fuse_layers)\n",
    "\n",
    "    def get_num_inchannels(self):\n",
    "        return self.num_inchannels\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.num_branches == 1:\n",
    "            return [self.branches[0](x[0])]\n",
    "\n",
    "        for i in range(self.num_branches):\n",
    "            x[i] = self.branches[i](x[i])\n",
    "\n",
    "        x_fuse = []\n",
    "\n",
    "        for i in range(len(self.fuse_layers)):\n",
    "            y = x[0] if i == 0 else self.fuse_layers[i][0](x[0])\n",
    "            for j in range(1, self.num_branches):\n",
    "                if i == j:\n",
    "                    y = y + x[j]\n",
    "                else:\n",
    "                    y = y + self.fuse_layers[i][j](x[j])\n",
    "            x_fuse.append(self.relu(y))\n",
    "\n",
    "        return x_fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_dict = {\n",
    "    'BASIC': BasicBlock,\n",
    "    'BOTTLENECK': Bottleneck\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseHighResolutionNet(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        self.inplanes = 64\n",
    "        extra = cfg['MODEL']['EXTRA']\n",
    "        super(PoseHighResolutionNet, self).__init__()\n",
    "\n",
    "        # stem net\n",
    "        self.conv1 = nn.Conv3d(1, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv3d(64, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(64, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(Bottleneck, 64, 4)\n",
    "\n",
    "        self.stage2_cfg = extra['STAGE2']\n",
    "        num_channels = self.stage2_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage2_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))\n",
    "        ]\n",
    "        self.transition1 = self._make_transition_layer([256], num_channels)\n",
    "        self.stage2, pre_stage_channels = self._make_stage(\n",
    "            self.stage2_cfg, num_channels)\n",
    "\n",
    "        self.stage3_cfg = extra['STAGE3']\n",
    "        num_channels = self.stage3_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage3_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))\n",
    "        ]\n",
    "        self.transition2 = self._make_transition_layer(\n",
    "            pre_stage_channels, num_channels)\n",
    "        self.stage3, pre_stage_channels = self._make_stage(\n",
    "            self.stage3_cfg, num_channels)\n",
    "\n",
    "        self.stage4_cfg = extra['STAGE4']\n",
    "        num_channels = self.stage4_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage4_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))\n",
    "        ]\n",
    "        self.transition3 = self._make_transition_layer(\n",
    "            pre_stage_channels, num_channels)\n",
    "        self.stage4, pre_stage_channels = self._make_stage(\n",
    "            self.stage4_cfg, num_channels, multi_scale_output=False)\n",
    "\n",
    "        self.final_layer = nn.Conv3d(\n",
    "            in_channels=pre_stage_channels[0],\n",
    "            out_channels=cfg['MODEL']['NUM_JOINTS'],\n",
    "            kernel_size=extra['FINAL_CONV_KERNEL'],\n",
    "            stride=1,\n",
    "            padding=1 if extra['FINAL_CONV_KERNEL'] == 3 else 0\n",
    "        )\n",
    "\n",
    "\n",
    "    def _make_transition_layer(\n",
    "            self, num_channels_pre_layer, num_channels_cur_layer):\n",
    "        num_branches_cur = len(num_channels_cur_layer)\n",
    "        num_branches_pre = len(num_channels_pre_layer)\n",
    "\n",
    "        transition_layers = []\n",
    "        for i in range(num_branches_cur):\n",
    "            if i < num_branches_pre:\n",
    "                if num_channels_cur_layer[i] != num_channels_pre_layer[i]:\n",
    "                    transition_layers.append(\n",
    "                        nn.Sequential(\n",
    "                            nn.Conv3d(\n",
    "                                num_channels_pre_layer[i],\n",
    "                                num_channels_cur_layer[i],\n",
    "                                3, 1, 1, bias=False\n",
    "                            ),\n",
    "                            nn.BatchNorm3d(num_channels_cur_layer[i]),\n",
    "                            nn.ReLU(inplace=True)\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    transition_layers.append(None)\n",
    "            else:\n",
    "                conv3x3s = []\n",
    "                for j in range(i+1-num_branches_pre):\n",
    "                    inchannels = num_channels_pre_layer[-1]\n",
    "                    outchannels = num_channels_cur_layer[i] \\\n",
    "                        if j == i-num_branches_pre else inchannels\n",
    "                    conv3x3s.append(\n",
    "                        nn.Sequential(\n",
    "                            nn.Conv3d(\n",
    "                                inchannels, outchannels, 3, 2, 1, bias=False\n",
    "                            ),\n",
    "                            nn.BatchNorm3d(outchannels),\n",
    "                            nn.ReLU(inplace=True)\n",
    "                        )\n",
    "                    )\n",
    "                transition_layers.append(nn.Sequential(*conv3x3s))\n",
    "\n",
    "        return nn.ModuleList(transition_layers)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(\n",
    "                    self.inplanes, planes * block.expansion,\n",
    "                    kernel_size=1, stride=stride, bias=False\n",
    "                ),\n",
    "                nn.BatchNorm3d(planes * block.expansion, momentum=BN_MOMENTUM),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_stage(self, layer_config, num_inchannels,\n",
    "                    multi_scale_output=True):\n",
    "        num_modules = layer_config['NUM_MODULES']\n",
    "        num_branches = layer_config['NUM_BRANCHES']\n",
    "        num_blocks = layer_config['NUM_BLOCKS']\n",
    "        num_channels = layer_config['NUM_CHANNELS']\n",
    "        block = blocks_dict[layer_config['BLOCK']]\n",
    "        fuse_method = layer_config['FUSE_METHOD']\n",
    "\n",
    "        modules = []\n",
    "        for i in range(num_modules):\n",
    "            # multi_scale_output is only used last module\n",
    "            if not multi_scale_output and i == num_modules - 1:\n",
    "                reset_multi_scale_output = False\n",
    "            else:\n",
    "                reset_multi_scale_output = True\n",
    "\n",
    "            modules.append(\n",
    "                HighResolutionModule(\n",
    "                    num_branches,\n",
    "                    block,\n",
    "                    num_blocks,\n",
    "                    num_inchannels,\n",
    "                    num_channels,\n",
    "                    fuse_method,\n",
    "                    reset_multi_scale_output\n",
    "                )\n",
    "            )\n",
    "            num_inchannels = modules[-1].get_num_inchannels()\n",
    "\n",
    "        return nn.Sequential(*modules), num_inchannels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage2_cfg['NUM_BRANCHES']):\n",
    "            if self.transition1[i] is not None:\n",
    "                x_list.append(self.transition1[i](x))\n",
    "            else:\n",
    "                x_list.append(x)\n",
    "        y_list = self.stage2(x_list)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage3_cfg['NUM_BRANCHES']):\n",
    "            if self.transition2[i] is not None:\n",
    "                x_list.append(self.transition2[i](y_list[-1]))\n",
    "            else:\n",
    "                x_list.append(y_list[i])\n",
    "        y_list = self.stage3(x_list)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage4_cfg['NUM_BRANCHES']):\n",
    "            if self.transition3[i] is not None:\n",
    "                x_list.append(self.transition3[i](y_list[-1]))\n",
    "            else:\n",
    "                x_list.append(y_list[i])\n",
    "        y_list = self.stage4(x_list)\n",
    "\n",
    "        x = self.final_layer(y_list[0])\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {'MODEL' : {'SIGMA': 2, 'EXTRA': {'FINAL_CONV_KERNEL': 1, 'STAGE2': {'NUM_CHANNELS': [32, 64], 'NUM_MODULES': 1, 'FUSE_METHOD': 'SUM', 'BLOCK': 'BASIC', 'NUM_BRANCHES': 2, 'NUM_BLOCKS': [4, 4]}, 'STAGE4': {'NUM_CHANNELS': [32, 64, 128, 256], 'NUM_MODULES': 3, 'FUSE_METHOD': 'SUM', 'BLOCK': 'BASIC', 'NUM_BRANCHES': 4, 'NUM_BLOCKS': [4, 4, 4, 4]}, 'STAGE3': {'NUM_CHANNELS': [32, 64, 128], 'NUM_MODULES': 4, 'FUSE_METHOD': 'SUM', 'BLOCK': 'BASIC', 'NUM_BRANCHES': 3, 'NUM_BLOCKS': [4, 4, 4]}}, 'NAME': 'pose_hrnet', 'HEATMAP_SIZE': [48, 64], 'PRETRAINED': 'models/pytorch/imagenet/hrnet_w32-36af842e.pth', 'INIT_WEIGHTS': True, 'TARGET_TYPE': 'gaussian', 'NUM_JOINTS': 1}}\n",
    "#(new_dict['MODEL']['EXTRA']['STAGE2']['NUM_CHANNELS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network:  84790049\n"
     ]
    }
   ],
   "source": [
    "net = PoseHighResolutionNet(cfg)\n",
    "n_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print('Number of parameters in network: ', n_params)\n",
    "#2d : 28536113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder that contains folders of segmentation data\n",
    "PATH = \"data/TrainingDataset_MSSEG/\"\n",
    "# Takes all folders in the path \n",
    "PATH = PATH + \"*/\"\n",
    "image_paths = []\n",
    "mask_paths = []\n",
    "\n",
    "block_size = (256,256,256)\n",
    "\n",
    "directory_paths = glob(PATH)\n",
    "for path in directory_paths:\n",
    "    # Load all the paths for each Flair set of data (1 Flair data and all its segmentation paths)\n",
    "    flair_path = path + '3DFLAIR.nii.gz'\n",
    "    seg1_path = path + 'ManualSegmentation_1.nii.gz'\n",
    "    seg2_path = path + 'ManualSegmentation_2.nii.gz'\n",
    "    seg3_path = path + 'ManualSegmentation_3.nii.gz'\n",
    "    seg4_path = path + 'ManualSegmentation_4.nii.gz'\n",
    "    seg5_path = path + 'ManualSegmentation_5.nii.gz'\n",
    "    seg6_path = path + 'ManualSegmentation_6.nii.gz'\n",
    "    seg7_path = path + 'ManualSegmentation_7.nii.gz'\n",
    "    image_paths.extend([flair_path,flair_path,flair_path,flair_path,flair_path,flair_path,flair_path])\n",
    "    mask_paths.extend([seg1_path,seg2_path,seg3_path,seg4_path,seg5_path,seg6_path,seg7_path])\n",
    "    \n",
    "#print(image_paths)\n",
    "#print(mask_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(image_paths, mask_paths, train_size):\n",
    "    img_paths_dic = {}\n",
    "    mask_paths_dic = {}\n",
    "    len_data = len(image_paths)\n",
    "    print('total len:', len_data)\n",
    "    p = 0\n",
    "    q = 0\n",
    "    for i in range(len(image_paths)):\n",
    "        img_paths_dic[str(p)+'_'+str(q)] = image_paths[i]\n",
    "        if q==6:\n",
    "            q=0\n",
    "            p=p+1\n",
    "        else:\n",
    "            q=q+1\n",
    "    \n",
    "    p = 0\n",
    "    q = 0\n",
    "    for i in range(len(mask_paths)):\n",
    "        mask_paths_dic[str(p)+'_'+str(q)] = mask_paths[i]\n",
    "        if q==6:\n",
    "            q=0\n",
    "            p=p+1\n",
    "        else:\n",
    "            q=q+1\n",
    "        \n",
    "    img_mask_list = []\n",
    "    #print(img_paths_dic)\n",
    "    \n",
    "    for key in img_paths_dic:\n",
    "        img_mask_list.append((img_paths_dic[key], mask_paths_dic[key]))\n",
    "        \n",
    "    train_img_mask_paths = img_mask_list[:int(len_data*train_size)] \n",
    "    val_img_mask_paths = img_mask_list[int(len_data*train_size):]\n",
    "    return train_img_mask_paths, val_img_mask_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_padding(data, block_size):\n",
    "    # Calculate final size to be achieved\n",
    "    ceil_val = math.ceil(data.shape[0]/block_size[0])\n",
    "    #Calculate required padding size \n",
    "    pad_val_c = (block_size[0] * ceil_val) - data.shape[0]\n",
    "    \n",
    "    # Calculate final size to be achieved\n",
    "    ceil_val = math.ceil(data.shape[1]/block_size[1])\n",
    "    #Calculate required padding size\n",
    "    pad_val_h = (block_size[1] * ceil_val) - data.shape[1]\n",
    "    \n",
    "    # Calculate final size to be achieved\n",
    "    ceil_val = math.ceil(data.shape[2]/block_size[2])\n",
    "    # Calculate required padding size\n",
    "    pad_val_w = (block_size[2] * ceil_val) - data.shape[2]\n",
    "    \n",
    "    # Constant padding\n",
    "    #data = data.numpy()\n",
    "    data = np.pad(data, ((0,pad_val_c),(0,pad_val_h),(0,pad_val_w)), 'constant')\n",
    "    #data = np.array(data, dtype=np.int16)\n",
    "    \n",
    "    #changed dtype to float\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_data_blocks(data, block_size ):\n",
    "    x = torch.from_numpy(data)\n",
    "    # Add a dimension at 0th position\n",
    "    x = x.unsqueeze(0)\n",
    "    # Kernel Size\n",
    "    kc, kh, kw = block_size[0], block_size[1], block_size[2]\n",
    "    # stride\n",
    "    dc, dh, dw = block_size[0], block_size[1], block_size[2]\n",
    "    patches = x.unfold(1, kc, dc).unfold(2, kh, dh).unfold(3, kw, dw)\n",
    "    unfold_shape = patches.size()\n",
    "    patches = patches.contiguous().view(patches.size(0), -1, kc, kh, kw)\n",
    "    #Return Patches and Unfold Shape\n",
    "    return patches, unfold_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_mask_paths):\n",
    "    img_mask_list = []\n",
    "\n",
    "    for i in tqdm(range(len(image_mask_paths))):\n",
    "        \n",
    "        #load the img and mask\n",
    "        vol = nib.load(image_mask_paths[i][0])\n",
    "        m = nib.load(image_mask_paths[i][1])\n",
    "        \n",
    "        # Get data, normalize the image and pad\n",
    "        img = np.array(vol.get_data(), np.float32) / 255.0\n",
    "        img_padded = zero_padding(img, block_size)\n",
    "        \n",
    "        mask = np.array(m.get_data(),np.uint8)\n",
    "        mask_padded = zero_padding(mask, block_size)\n",
    "\n",
    "        # Generate data blocks of block_size\n",
    "        img_blocks, unfold_shape_img = get_data_blocks(data = img_padded, block_size = block_size)\n",
    "        mask_blocks, unfold_shape_mask = get_data_blocks(data = mask_padded, block_size = block_size)\n",
    "\n",
    "        img_array = img_blocks.numpy()\n",
    "        mask_array = mask_blocks.numpy()\n",
    "\n",
    "        for i in range(len(img_array[0])):\n",
    "            img_mask_list.append((img_array[0][i], mask_array[0][i]))\n",
    "\n",
    "    return img_mask_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total len: 3\n",
      "['data/TrainingDataset_MSSEG/08027SYBR/3DFLAIR.nii.gz', 'data/TrainingDataset_MSSEG/08027SYBR/3DFLAIR.nii.gz', 'data/TrainingDataset_MSSEG/08027SYBR/3DFLAIR.nii.gz']\n",
      "['data/TrainingDataset_MSSEG/08027SYBR/ManualSegmentation_1.nii.gz', 'data/TrainingDataset_MSSEG/08027SYBR/ManualSegmentation_2.nii.gz', 'data/TrainingDataset_MSSEG/08027SYBR/ManualSegmentation_3.nii.gz']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:06<00:00,  3.26s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.18s/it]\n"
     ]
    }
   ],
   "source": [
    "train_img_mask_paths, val_img_mask_paths = split_train_val(image_paths[:3], mask_paths[:3], 0.95)\n",
    "print(image_paths[:3])\n",
    "print(mask_paths[:3])\n",
    "\n",
    "#Training:\n",
    "train_img_masks = preprocess_image(train_img_mask_paths)\n",
    "\n",
    "\n",
    "#Validation:\n",
    "val_img_masks = preprocess_image(val_img_mask_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For validation data\n",
    "# val_img_masks_save_path = '/scratch/srm714/data/train_img_masks.pickle'\n",
    "# if os.path.exists(val_img_masks_save_path):\n",
    "#     with open(val_img_masks_save_path,'rb') as f:\n",
    "#         val_img_masks = pickle.load(f)\n",
    "#     f.close()\n",
    "# else:\n",
    "#     val_img_masks = preprocess_image(val_img_mask_paths)\n",
    "#     pickle_store(val_img_masks_save_path,val_img_masks)\n",
    "# print('val len: {}'.format(len(val_img_masks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"\n",
    "    Convert ndarrays in sample to Tensors.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['img'], sample['label']\n",
    "        image = image[None,:,:]\n",
    "        label = label[None,:,:]\n",
    "\n",
    "        return {'img': torch.from_numpy(image.copy()).type(torch.FloatTensor),\n",
    "                'label': torch.from_numpy(label.copy()).type(torch.FloatTensor)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_masks, transforms=None):\n",
    "\n",
    "        self.image_masks = image_masks\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):  # return count of sample we have\n",
    "\n",
    "        return len(self.image_masks)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image = self.image_masks[index][0] # H, W, C\n",
    "        mask = self.image_masks[index][1]\n",
    "\n",
    "#       image = np.transpose(image, axes=[2, 0, 1]) # C, H, W\n",
    "\n",
    "        sample = {'img': image, 'label': mask}\n",
    "\n",
    "        if transforms:\n",
    "            sample = self.transforms(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "train_dataset = CustomDataset(train_img_masks, transforms=transforms.Compose([ToTensor()]))\n",
    "val_dataset = CustomDataset(val_img_masks, transforms=transforms.Compose([ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define dice coefficient \n",
    "class DiceCoeff(Function):\n",
    "    \"\"\"Dice coeff for one pair of input image and target image\"\"\"\n",
    "    def forward(self, prediction, target):\n",
    "        self.save_for_backward(prediction, target)\n",
    "        eps = 0.0001 # in case union = 0\n",
    "        # Calculate intersection and union. \n",
    "        # You can convert the input image into a vector with input.contiguous().view(-1)\n",
    "        # Then use torch.dot(A, B) to calculate the intersection.\n",
    "        A = prediction.view(-1)\n",
    "        B = target.view(-1)\n",
    "        inter = torch.dot(A.float(),B.float())\n",
    "        union = torch.sum(A.float()) + torch.sum(B.float()) - inter + eps\n",
    "        # Calculate DICE \n",
    "        d = inter / union\n",
    "        return d\n",
    "\n",
    "# Calculate dice coefficients for batches\n",
    "def dice_coeff(prediction, target):\n",
    "    \"\"\"Dice coeff for batches\"\"\"\n",
    "    s = torch.FloatTensor(1).zero_()\n",
    "    \n",
    "    # For each pair of input and target, call DiceCoeff().forward(prediction, target) to calculate dice coefficient\n",
    "    # Then average\n",
    "    for i, (a,b) in enumerate(zip(prediction, target)):\n",
    "        s += DiceCoeff().forward(a,b)\n",
    "    s = s / (i + 1)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(net, dataset):\n",
    "    # set net mode to evaluation\n",
    "    net.eval()\n",
    "    tot = 0\n",
    "    print('Validation began')\n",
    "    print('val len: ', len(dataset))\n",
    "    print(next(net.parameters()).is_cuda)\n",
    "    for i, b in enumerate(dataset):\n",
    "        img = b['img'].to(device)\n",
    "        B = img.shape[0]\n",
    "        true_mask = b['label'].to(device)\n",
    "\n",
    "        # Feed the image to the network to get predicted mask\n",
    "        mask_pred = net.forward(img.float())\n",
    "        print('predicted')\n",
    "        \n",
    "        # For all pixels in predicted mask, set them to 1 if larger than 0.5. Otherwise set them to 0\n",
    "        #mask_pred = mask_pred > 0.5\n",
    "        \n",
    "        # calculate dice_coeff()\n",
    "        # note that you should add all the dice_coeff in validation/testing dataset together\n",
    "        # call dice_coeff() here\n",
    "        masks_probs_flat = mask_pred.view(mask_pred.numel())\n",
    "        true_masks_flat = true_mask.view(true_mask.numel())\n",
    "        \n",
    "        tot += dice_coeff(true_masks_flat,masks_probs_flat)\n",
    "        print('tot: ',tot)\n",
    "        #tot += dice_coeff(true_mask,mask_pred)\n",
    "        # Return average dice_coeff()\n",
    "    print('Validation done!')\n",
    "    return tot / (i + 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/2.\n",
      "train len:  16\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 11.17 GiB total capacity; 10.64 GiB already allocated; 117.75 MiB free; 10.75 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-762cf1b4db0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Feed your images into the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mmasks_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mmasks_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasks_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mmasks_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasks_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-4b78a89140a0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/py3.6.3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/py3.6.3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    479\u001b[0m                             self.dilation, self.groups)\n\u001b[1;32m    480\u001b[0m         return F.conv3d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 481\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 11.17 GiB total capacity; 10.64 GiB already allocated; 117.75 MiB free; 10.75 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "epochs = 2 # e.g. 10, or more until dice converge\n",
    "batch_size = 1 # e.g. 16\n",
    "lr = 0.01        # e.g. 0.01, 0.00001\n",
    "N_train = len(train_img_masks)\n",
    "model_save_path = 'model/'  # directory to same the model after each epoch.\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(),lr = lr,momentum=0.99, weight_decay=0.0005)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "net.to(device)\n",
    "\n",
    "# Start training\n",
    "for epoch in range(epochs):\n",
    "    print('Starting epoch {}/{}.'.format(epoch + 1, epochs))\n",
    "    net.train()\n",
    "    # Reload images and masks for training and validation and perform random shuffling at the begining of each epoch\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=7)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=7)\n",
    "\n",
    "    epoch_loss = 0\n",
    "    count = 0\n",
    "    print('train len: ', len(train_loader))\n",
    "\n",
    "    for i, b in enumerate(train_loader):\n",
    "        # Get images and masks from each batch\n",
    "        imgs = b['img']\n",
    "        true_masks = b['label']\n",
    "        \n",
    "        imgs = imgs.to(device)\n",
    "        true_masks = true_masks.to(device)\n",
    "        #print('True mask shape: ',true_masks.shape)\n",
    "\n",
    "        # Feed your images into the network\n",
    "        masks_pred = net.forward(imgs.float())\n",
    "        masks_probs = masks_pred[:,0,:,:,:]\n",
    "        masks_probs = masks_probs.unsqueeze(1)\n",
    "\n",
    "        masks_probs_flat = masks_probs.reshape(1,-1)\n",
    "        masks_probs_flat = masks_probs_flat.squeeze()\n",
    "\n",
    "        true_masks_flat = true_masks.reshape(1,-1)\n",
    "        true_masks_flat = true_masks_flat.squeeze()\n",
    "\n",
    "        # Calculate the loss by comparing the predicted masks vector and true masks vector\n",
    "        # And sum the losses together\n",
    "        loss = criterion(masks_probs_flat,true_masks_flat.float())\n",
    "        epoch_loss += loss.item()\n",
    "        if count % 50 == 0:\n",
    "            print('{0:.4f} --- loss: {1:.6f}'.format(i * batch_size / N_train, loss.item()))\n",
    "        count = count + 1\n",
    "        # optimizer.zero_grad() clears x.grad for every parameter x in the optimizer.\n",
    "        # It’s important to call this before loss.backward(), otherwise you’ll accumulate the gradients from multiple passes.\n",
    "        optimizer.zero_grad()\n",
    "        # loss.backward() computes dloss/dx for every parameter x which has requires_grad=True.\n",
    "        # These are accumulated into x.grad for every parameter x\n",
    "        loss.backward()\n",
    "        # optimizer.step updates the value of x using the gradient x.grad.\n",
    "        optimizer.step()\n",
    "    print('Epoch finished ! Loss: {}'.format(epoch_loss / i))\n",
    "\n",
    "    # Perform validation with eval_net() on the validation data\n",
    "    #val_dice = eval_net(net,val_loader)\n",
    "    #print('Validation Dice Coeff: {}'.format(val_dice))\n",
    "    \n",
    "    # Save the model after each epoch\n",
    "    if os.path.isdir(model_save_path):\n",
    "        torch.save(net.state_dict(),model_save_path + 'Brain_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "    else:\n",
    "        os.makedirs(model_save_path, exist_ok=True)\n",
    "        torch.save(net.state_dict(),model_save_path + 'Brain_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "    print('Checkpoint {} saved !'.format(epoch + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
